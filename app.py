# app.py
"""
Streamlit English Pronunciation Coach
Features:
 - Hybrid ?word=... prefill + editable text_input
 - Language selection (?lang=... fallback to sidebar)
 - st.audio_input recording with file upload fallback
 - Whisper-1 transcription
 - GPT-4o-mini analysis in requested language (JSON preferred)
 - IPA hints (generated by GPT)
 - Save session results to SQLite (audio saved locally)
 - Student history + download CSV
 - Teacher dashboard (password via st.secrets["TEACHER_PASSWORD"])
"""

import streamlit as st
import tempfile
import difflib
import html
import json
import time
import os
import sqlite3
import pandas as pd
from pathlib import Path
from typing import Tuple, Optional, Dict, Any, List
from openai import OpenAI

# ------------------ Configuration ------------------
DB_PATH = Path("pronunciation_results.db")
AUDIO_DIR = Path("saved_audio")
AUDIO_DIR.mkdir(exist_ok=True)

st.set_page_config(page_title="English Pronunciation Coach", layout="wide")

# ------------------ Utilities ------------------
def init_db():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """
        CREATE TABLE IF NOT EXISTS sessions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            student_name TEXT,
            target_text TEXT,
            language TEXT,
            transcript TEXT,
            local_accuracy INTEGER,
            char_similarity INTEGER,
            ai_accuracy INTEGER,
            mistakes TEXT,
            detailed_feedback TEXT,
            corrections TEXT,
            ipa TEXT,
            audio_path TEXT,
            created_at TEXT
        )
        """
    )
    conn.commit()
    conn.close()

def save_session(record: dict):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """
        INSERT INTO sessions (
            student_name, target_text, language, transcript,
            local_accuracy, char_similarity, ai_accuracy, mistakes,
            detailed_feedback, corrections, ipa, audio_path, created_at
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """,
        (
            record.get("student_name"),
            record.get("target_text"),
            record.get("language"),
            record.get("transcript"),
            record.get("local_accuracy"),
            record.get("char_similarity"),
            record.get("ai_accuracy"),
            json.dumps(record.get("mistakes", []), ensure_ascii=False),
            record.get("detailed_feedback"),
            record.get("corrections"),
            record.get("ipa"),
            record.get("audio_path"),
            record.get("created_at"),
        ),
    )
    conn.commit()
    conn.close()

def fetch_sessions(limit: int = 100, filters: dict = None) -> pd.DataFrame:
    conn = sqlite3.connect(DB_PATH)
    query = "SELECT * FROM sessions"
    conditions = []
    params = []
    if filters:
        if filters.get("student_name"):
            conditions.append("student_name LIKE ?")
            params.append(f"%{filters['student_name']}%")
        if filters.get("language"):
            conditions.append("language = ?")
            params.append(filters["language"])
        if filters.get("date_from"):
            conditions.append("date(created_at) >= date(?)")
            params.append(filters["date_from"])
        if filters.get("date_to"):
            conditions.append("date(created_at) <= date(?)")
            params.append(filters["date_to"])
    if conditions:
        query += " WHERE " + " AND ".join(conditions)
    query += " ORDER BY created_at DESC LIMIT ?"
    params.append(limit)
    df = pd.read_sql_query(query, conn, params=params)
    conn.close()
    return df

def word_level_diff_html(target: str, spoken: str) -> Tuple[str, str, int]:
    target_words = [w for w in target.strip().split() if w != ""]
    spoken_words = [w for w in spoken.strip().split() if w != ""]
    sm = difflib.SequenceMatcher(a=target_words, b=spoken_words)
    target_html_parts = []
    spoken_html_parts = []
    matched = 0
    for tag, i1, i2, j1, j2 in sm.get_opcodes():
        if tag == "equal":
            for w in target_words[i1:i2]:
                target_html_parts.append(f'<span style="background:#d4f8d4;padding:4px;border-radius:4px;margin:2px;display:inline-block;">{html.escape(w)}</span>')
            for w in spoken_words[j1:j2]:
                spoken_html_parts.append(f'<span style="background:#d4f8d4;padding:4px;border-radius:4px;margin:2px;display:inline-block;">{html.escape(w)}</span>')
            matched += (i2 - i1)
        elif tag == "replace":
            for w in target_words[i1:i2]:
                target_html_parts.append(f'<span style="background:#ffd6d6;padding:4px;border-radius:4px;margin:2px;display:inline-block;color:#b30000;">{html.escape(w)}</span>')
            for w in spoken_words[j1:j2]:
                spoken_html_parts.append(f'<span style="background:#ffd6d6;padding:4px;border-radius:4px;margin:2px;display:inline-block;color:#b30000;">{html.escape(w)}</span>')
        elif tag == "delete":
            for w in target_words[i1:i2]:
                target_html_parts.append(f'<span style="background:#ffd6d6;padding:4px;border-radius:4px;margin:2px;display:inline-block;color:#b30000;text-decoration:line-through;">{html.escape(w)}</span>')
        elif tag == "insert":
            for w in spoken_words[j1:j2]:
                spoken_html_parts.append(f'<span style="background:#ffd6d6;padding:4px;border-radius:4px;margin:2px;display:inline-block;color:#b30000;">{html.escape(w)}</span>')
    target_html = " ".join(target_html_parts) if target_html_parts else "<i>(no words)</i>"
    spoken_html = " ".join(spoken_html_parts) if spoken_html_parts else "<i>(no words)</i>"
    target_count = max(1, len(target_words))
    accuracy_pct = int(round((matched / target_count) * 100))
    return target_html, spoken_html, accuracy_pct

def compute_char_similarity(a: str, b: str) -> int:
    sm = difflib.SequenceMatcher(None, a.strip().lower(), b.strip().lower())
    return int(round(sm.ratio() * 100))

def safe_parse_json_from_text(text: str) -> Optional[dict]:
    if not text:
        return None
    # find first '{' and last '}'
    start = text.find("{")
    end = text.rfind("}")
    if start == -1 or end == -1:
        # try direct parse
        try:
            return json.loads(text)
        except:
            return None
    candidate = text[start:end+1]
    try:
        return json.loads(candidate)
    except:
        # fallback: try to be more permissive with single quotes
        try:
            candidate2 = candidate.replace("'", '"')
            return json.loads(candidate2)
        except:
            return None

# ------------------ Initialize DB ------------------
init_db()

# ------------------ Page UI ------------------
st.title("ðŸŽ§ English Pronunciation Coach â€” All-in-One Edition")
st.write("Practice pronunciation, get IPA hints, save student sessions, and use a teacher dashboard to review results.")

# Query params
query_params = st.experimental_get_query_params()
url_word = query_params.get("word", ["Hello"])[0] if query_params.get("word") else "Hello"
url_lang = query_params.get("lang", ["Amharic"])[0] if query_params.get("lang") else "Amharic"

# Sidebar controls (including teacher login)
with st.sidebar:
    st.header("Settings")
    st.markdown("Use URL `?word=...&lang=...` to prefill the practice word and language.")
    lang = st.selectbox("Feedback language", options=["Amharic", "Oromiffa", "Arabic", "English"], index=["Amharic","Oromiffa","Arabic","English"].index(url_lang) if url_lang in ["Amharic","Oromiffa","Arabic","English"] else 0)
    st.markdown("---")
    st.subheader("Student / Session")
    student_name = st.text_input("Student name (optional)", value="")
    st.markdown("---")
    st.subheader("Teacher Dashboard")
    teacher_mode = st.checkbox("Open Teacher Dashboard")
    teacher_password_entered = ""
    if teacher_mode:
        teacher_password_entered = st.text_input("Teacher password", type="password")
        st.markdown("If you don't have `TEACHER_PASSWORD` in secrets, teacher dashboard is not accessible.")

# Instructions in selected language
if lang.lower().startswith("amhar"):
    st.info("áŠ¥á‰£áŠ­á‹Ž á‰ƒáˆ‰áŠ• á‹ˆá‹­áˆ áŠ áŠ•á‹³áŠ•á‹µ áˆ•áŒ‹á‹Š á‹ˆáˆ¨á‰€á‰µ á‹«áˆµáŒˆá‰¡á¢ á‹µáˆáŒ½á‹ŽáŠ• á‹­á‰…áˆ¨áŒ¹á£ áŠ¥áŠ“ áŠ¥áŠ•á‹²áˆ áˆ˜áˆáˆµ á‰ á‹­áˆáŠ•á¢")
elif lang.lower().startswith("orom"):
    st.info("Jecha barreessi, sagalee kee galchi, deebii argadhu.")
elif lang.lower().startswith("arab"):
    st.info("ïº¢ïº‹ïºŽïº¼ï»§ï»­ ïº¢ï»´ïº¤ïº¼ïº— ï»°ï» ï»‹ ï»žïº¼ïº¤ïº˜ï»Ÿ ï»šïº—ï»®ïº» ï»žïº ïº³ï»­ ïºŽï»¬ï»´ï» ï»‹ ïºï»³ïº­ïºªïº˜ï»Ÿïº ïº©ïºïº®ï»¤ï»Ÿïº ïº”ï» ï»¤ïº ï»Ÿïº ï»­ïºƒ ïº”ï»¤ï» ï»œï»Ÿïº ïºïº˜ï»›ïº.")
else:
    st.info("Type the word or sentence and record your voice. You will receive corrections and tips.")

# Target text input (hybrid: URL param prefill + editable)
target_text = st.text_input("Target word / sentence", value=url_word)

st.markdown("---")

# Audio input
st.subheader("Record your pronunciation")
st.write("Use the Record button to capture your voice. If `st.audio_input` isn't available, upload a file.")
audio_bytes = None
try:
    audio_bytes = st.audio_input("Record here")
except Exception:
    st.warning("`st.audio_input` not available â€” use the uploader below.")
    uploaded = st.file_uploader("Upload audio (wav/mp3/m4a/ogg)", type=["wav","mp3","m4a","ogg"])
    if uploaded:
        audio_bytes = uploaded.read()

# Analyze button
analyze = st.button("Analyze & Save")

# Teacher: view dashboard if requested and password correct
teacher_allowed = False
if teacher_mode:
    if "TEACHER_PASSWORD" in st.secrets:
        if teacher_password_entered == st.secrets["TEACHER_PASSWORD"]:
            teacher_allowed = True
        else:
            st.sidebar.error("Teacher password incorrect.")
    else:
        st.sidebar.warning("No TEACHER_PASSWORD in st.secrets â€” set it to enable dashboard.")

# OpenAI client helper
def get_openai_client():
    if "OPENAI_API_KEY" not in st.secrets:
        st.error("Add your OpenAI key to st.secrets['OPENAI_API_KEY'].")
        st.stop()
    return OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# Function: transcribe with Whisper
def transcribe_audio(openai_client: OpenAI, audio_path: str) -> str:
    try:
        resp = openai_client.audio.transcriptions.create(model="whisper-1", file=open(audio_path, "rb"))
        # resp may be an object with 'text'
        if hasattr(resp, "text"):
            return resp.text
        if isinstance(resp, dict) and "text" in resp:
            return resp["text"]
        return str(resp)
    except Exception as e:
        st.error(f"Transcription error: {e}")
        return ""

# Function: ask GPT to analyze pronunciation and produce IPA and JSON
def ask_gpt_analysis(openai_client: OpenAI, target: str, transcript: str, language: str) -> Dict[str, Any]:
    # System prompt: instruct to reply only in JSON and in the requested language
    system_prompt = (
        f"You are a friendly, encouraging pronunciation coach. "
        f"Provide feedback and corrections in {language}. "
        f"Return a STRICT JSON object (no extra text) with keys:\n"
        f'  - "accuracy_percent": number (0-100),\n'
        f'  - "mistakes": array of short strings describing specific pronunciation mistakes,\n'
        f'  - "detailed_feedback": short paragraph in {language} with tips,\n'
        f'  - "corrections": optional string with example words or phonetic hints (IPA allowed),\n'
        f'  - "ipa": optional IPA/transcription for the target text,\n'
        f'  - "display": optional short message.\n'
        f'If full JSON cannot be provided, still return the JSON object as the only content. Use UTF-8 and preserve non-Latin characters.'
    )

    user_prompt = (
        f"Target text: {target}\n\n"
        f"Spoken (transcription): {transcript}\n\n"
        f"Analyze the pronunciation and produce the JSON described. Also include an 'ipa' field with phonetic transcription (IPA) or phonetic hint for the target text."
    )

    try:
        resp = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=600,
            temperature=0.2,
        )
        # extract text
        content = ""
        if hasattr(resp, "choices") and len(resp.choices) > 0:
            first = resp.choices[0]
            # SDKs may differ
            try:
                content = first.message.get("content") if getattr(first, "message", None) else str(first)
            except Exception:
                content = str(first)
        else:
            content = str(resp)
        parsed = safe_parse_json_from_text(content)
        if parsed:
            return parsed
        else:
            # fallback: put raw text into detailed_feedback in returned dict
            return {"detailed_feedback": content}
    except Exception as e:
        st.error(f"AI analysis error: {e}")
        return {"detailed_feedback": f"AI error: {e}"}

# ------------------ Main: Analyze Flow ------------------
if analyze:
    if not audio_bytes:
        st.error("No audio captured or uploaded. Please record or upload an audio file.")
    else:
        # Save audio_bytes to file
        ts = int(time.time())
        safe_student = (student_name.strip() or "anonymous").replace(" ", "_")
        filename = AUDIO_DIR / f"{safe_student}_{ts}.webm"
        try:
            # audio_bytes may be bytes or UploadedFile-like
            if isinstance(audio_bytes, (bytes, bytearray)):
                filename.write_bytes(audio_bytes)
            else:
                # Streamlit's st.audio_input returns an UploadedFile-like object
                try:
                    filename.write_bytes(audio_bytes.getvalue())
                except Exception:
                    # file-like object
                    with open(filename, "wb") as f:
                        f.write(audio_bytes.read())
        except Exception as e:
            st.error(f"Failed to save audio: {e}")
            filename = None

        # Create OpenAI client and transcribe
        client = get_openai_client()
        transcript = transcribe_audio(client, str(filename)) if filename else ""

        # Local diffs & metrics
        target_html, spoken_html, local_accuracy = word_level_diff_html(target_text, transcript)
        char_similarity = compute_char_similarity(target_text, transcript)

        # Ask GPT for analysis + IPA
        ai_result = ask_gpt_analysis(client, target_text, transcript, lang)
        ai_accuracy = ai_result.get("accuracy_percent")
        mistakes = ai_result.get("mistakes", [])
        detailed_feedback = ai_result.get("detailed_feedback", "")
        corrections = ai_result.get("corrections", "")
        ipa = ai_result.get("ipa", "")

        # Show results
        st.markdown("## Results")
        left, right = st.columns([1,1])
        with left:
            st.markdown("### ðŸŽ¯ Target")
            st.markdown(target_html, unsafe_allow_html=True)
            st.markdown("**IPA / phonetic hint**")
            if ipa:
                st.code(ipa)
            else:
                st.write("_No IPA returned by AI._")
        with right:
            st.markdown("### ðŸ—£ What you said (transcription)")
            st.markdown(spoken_html, unsafe_allow_html=True)
            st.write(f"**Transcript:** {transcript}")

        st.metric("Local word accuracy", f"{local_accuracy}%")
        st.metric("Character similarity", f"{char_similarity}%")
        if ai_accuracy is not None:
            st.metric("AI accuracy estimate", f"{ai_accuracy}%")

        if mistakes:
            st.subheader("Specific mistakes")
            for m in mistakes:
                st.write("â€¢", m)

        if detailed_feedback:
            st.subheader("Coaching feedback")
            st.write(detailed_feedback)

        if corrections:
            st.subheader("Corrections / Examples")
            st.write(corrections)

        # Save session in DB
        record = {
            "student_name": student_name.strip() or "anonymous",
            "target_text": target_text,
            "language": lang,
            "transcript": transcript,
            "local_accuracy": local_accuracy,
            "char_similarity": char_similarity,
            "ai_accuracy": ai_accuracy if ai_accuracy is not None else None,
            "mistakes": mistakes,
            "detailed_feedback": detailed_feedback,
            "corrections": corrections,
            "ipa": ipa,
            "audio_path": str(filename) if filename else "",
            "created_at": time.strftime("%Y-%m-%d %H:%M:%S"),
        }
        save_session(record)
        st.success("Session saved.")

        # Provide audio download
        if filename and filename.exists():
            with open(filename, "rb") as f:
                audio_data = f.read()
            st.download_button("Download recorded audio", data=audio_data, file_name=filename.name, mime="audio/webm")

        # Offer CSV download of LAST 100 entries (including this one)
        df_latest = fetch_sessions(limit=100)
        csv = df_latest.to_csv(index=False)
        st.download_button("Download recent sessions as CSV", data=csv.encode("utf-8"), file_name="pronunciation_sessions.csv", mime="text/csv")

# ------------------ Teacher Dashboard ------------------
if teacher_allowed:
    st.sidebar.success("Teacher dashboard unlocked.")
    st.header("ðŸ“Š Teacher Dashboard")
    # Filters
    colf1, colf2, colf3, colf4 = st.columns([2,2,2,2])
    with colf1:
        f_name = st.text_input("Filter: student name contains", value="")
    with colf2:
        f_lang = st.selectbox("Filter: language", options=["", "Amharic", "Oromiffa", "Arabic", "English"])
    with colf3:
        f_date_from = st.date_input("From (date)", value=None)
    with colf4:
        f_date_to = st.date_input("To (date)", value=None)

    filters = {}
    if f_name:
        filters["student_name"] = f_name
    if f_lang:
        filters["language"] = f_lang
    if f_date_from:
        filters["date_from"] = f_date_from.isoformat()
    if f_date_to:
        filters["date_to"] = f_date_to.isoformat()

    limit = st.number_input("Max rows to fetch", min_value=10, max_value=1000, value=200, step=10)
    df = fetch_sessions(limit=int(limit), filters=filters if filters else None)

    st.write(f"Showing {len(df)} sessions")
    if not df.empty:
        # Show table (with audio download links)
        df_display = df.copy()
        # shorten mistakes column for display
        df_display["mistakes"] = df_display["mistakes"].apply(lambda x: (x[:200] + "...") if isinstance(x, str) and len(x) > 200 else x)
        st.dataframe(df_display)

        # CSV download for teacher
        st.download_button("Download filtered CSV", data=df.to_csv(index=False).encode("utf-8"), file_name="teacher_filtered_sessions.csv", mime="text/csv")

        # For each row, show audio download if exists
        st.markdown("---")
        st.subheader("Audio files")
        for idx, row in df.iterrows():
            audio_path = row.get("audio_path")
            student = row.get("student_name", "")
            created = row.get("created_at", "")
            if audio_path and Path(audio_path).exists():
                with open(audio_path, "rb") as f:
                    audio_bytes_local = f.read()
                st.write(f"Student: **{student}** â€” {created} â€” file: `{Path(audio_path).name}`")
                st.audio(audio_bytes_local)
                st.download_button(f"Download {Path(audio_path).name}", data=audio_bytes_local, file_name=Path(audio_path).name, mime="audio/webm")
            else:
                st.write(f"Student: **{student}** â€” {created} â€” (no audio)")

    else:
        st.info("No sessions match the current filters.")

# ------------------ Footer / Help ------------------
st.markdown("---")
st.markdown("**Notes & deployment**")
st.markdown(
    """
- Put your OpenAI API key in `st.secrets['OPENAI_API_KEY']`.  
- (Optional) Add `st.secrets['TEACHER_PASSWORD']` to enable the password-protected teacher dashboard.  
- The app saves audio files locally to `saved_audio/` and sessions to `pronunciation_results.db`.  
- For Streamlit Cloud deploy, add secrets in the Cloud UI. `requirements.txt` below lists needed packages.
"""
)

